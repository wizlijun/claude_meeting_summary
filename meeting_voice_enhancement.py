#!/usr/bin/env python3
"""
ä¼šè®®å£°çº¹å¢å¼ºæ¨¡å—
ç”¨äºæå‡ä¼šè®®ä¸­è¯´è¯äººè¯†åˆ«çš„ç²¾åº¦
"""

import os
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging

try:
    from resemblyzer import VoiceEncoder, preprocess_wav
    import librosa
    RESEMBLYZER_AVAILABLE = True
except ImportError:
    RESEMBLYZER_AVAILABLE = False
    print("è­¦å‘Š: Resemblyzeråº“ä¸å¯ç”¨ï¼Œè¯·è¿è¡Œ 'pip install resemblyzer'")

logger = logging.getLogger(__name__)


class MeetingVoiceEnhancer:
    """ä¼šè®®å£°çº¹å¢å¼ºå™¨"""
    
    def __init__(self, speaker_dir: str = "speaker", threshold: float = 0.75):
        """
        åˆå§‹åŒ–ä¼šè®®å£°çº¹å¢å¼ºç³»ç»Ÿ
        
        Args:
            speaker_dir: è¯´è¯äººæ ·æœ¬éŸ³é¢‘ç›®å½•
            threshold: å£°çº¹åŒ¹é…ç›¸ä¼¼åº¦é˜ˆå€¼
        """
        if not RESEMBLYZER_AVAILABLE:
            raise ImportError("Resemblyzeråº“ä¸å¯ç”¨ï¼Œè¯·è¿è¡Œ 'pip install resemblyzer'")
        
        self.speaker_dir = Path(speaker_dir)
        self.threshold = threshold
        self.voice_encoder = VoiceEncoder()
        
        # å­˜å‚¨è¯´è¯äººåµŒå…¥å‘é‡
        self.speaker_embeddings = {}
        self.speaker_names = []
        
        # åŠ è½½å·²çŸ¥è¯´è¯äºº
        self._load_speaker_profiles()
    
    def _load_speaker_profiles(self):
        """åŠ è½½å·²çŸ¥è¯´è¯äººçš„å£°çº¹æ¡£æ¡ˆ"""
        if not self.speaker_dir.exists():
            logger.warning(f"è¯´è¯äººç›®å½•ä¸å­˜åœ¨: {self.speaker_dir}")
            return
        
        wav_files = list(self.speaker_dir.glob("*.wav"))
        logger.info(f"å‘ç° {len(wav_files)} ä¸ªè¯´è¯äººæ ·æœ¬æ–‡ä»¶")
        
        for wav_file in wav_files:
            speaker_name = wav_file.stem
            try:
                # åŠ è½½å’Œé¢„å¤„ç†éŸ³é¢‘
                wav, sr = librosa.load(str(wav_file), sr=16000)
                wav = preprocess_wav(wav)
                
                # æå–å£°çº¹åµŒå…¥å‘é‡
                embedding = self.voice_encoder.embed_utterance(wav)
                
                self.speaker_embeddings[speaker_name] = embedding
                self.speaker_names.append(speaker_name)
                
                logger.info(f"å·²åŠ è½½è¯´è¯äººå£°çº¹: {speaker_name}")
                
            except Exception as e:
                logger.error(f"åŠ è½½è¯´è¯äºº {speaker_name} å¤±è´¥: {e}")
        
        print(f"âœ“ æˆåŠŸåŠ è½½ {len(self.speaker_embeddings)} ä¸ªè¯´è¯äººå£°çº¹æ¡£æ¡ˆ")
    
    def _extract_segment_embedding(self, audio_data: np.ndarray, start_time: float, end_time: float, sample_rate: int = 16000) -> Optional[np.ndarray]:
        """
        æå–éŸ³é¢‘ç‰‡æ®µçš„å£°çº¹åµŒå…¥å‘é‡
        
        Args:
            audio_data: å®Œæ•´éŸ³é¢‘æ•°æ®
            start_time: å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
            end_time: ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
            sample_rate: é‡‡æ ·ç‡
            
        Returns:
            å£°çº¹åµŒå…¥å‘é‡æˆ–None
        """
        try:
            # è®¡ç®—æ ·æœ¬ç´¢å¼•
            start_sample = int(start_time * sample_rate)
            end_sample = int(end_time * sample_rate)
            
            # æå–éŸ³é¢‘ç‰‡æ®µ
            segment = audio_data[start_sample:end_sample]
            
            # ç¡®ä¿ç‰‡æ®µé•¿åº¦è¶³å¤Ÿ
            if len(segment) < sample_rate * 0.5:  # è‡³å°‘0.5ç§’
                return None
            
            # é¢„å¤„ç†éŸ³é¢‘ç‰‡æ®µ
            segment = preprocess_wav(segment)
            
            # æå–åµŒå…¥å‘é‡
            embedding = self.voice_encoder.embed_utterance(segment)
            
            return embedding
            
        except Exception as e:
            logger.error(f"æå–ç‰‡æ®µåµŒå…¥å‘é‡å¤±è´¥: {e}")
            return None
    
    def _identify_speaker(self, segment_embedding: np.ndarray) -> Tuple[Optional[str], float]:
        """
        æ ¹æ®åµŒå…¥å‘é‡è¯†åˆ«è¯´è¯äºº
        
        Args:
            segment_embedding: éŸ³é¢‘ç‰‡æ®µçš„åµŒå…¥å‘é‡
            
        Returns:
            (è¯´è¯äººåç§°, ç›¸ä¼¼åº¦åˆ†æ•°)
        """
        if not self.speaker_embeddings:
            return None, 0.0
        
        best_match = None
        best_similarity = 0.0
        
        for speaker_name, known_embedding in self.speaker_embeddings.items():
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            similarity = np.dot(segment_embedding, known_embedding)
            
            if similarity > best_similarity and similarity > self.threshold:
                best_similarity = similarity
                best_match = speaker_name
        
        return best_match, best_similarity
    
    def enhance_speaker_identification(self, segments: List[Dict], audio_file: str) -> List[Dict]:
        """
        ä½¿ç”¨Resemblyzerå¢å¼ºè¯´è¯äººè¯†åˆ«
        
        Args:
            segments: å¸¦æœ‰pyannoteè¯´è¯äººæ ‡ç­¾çš„ç‰‡æ®µåˆ—è¡¨
            audio_file: åŸå§‹éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            å¢å¼ºåçš„ç‰‡æ®µåˆ—è¡¨
        """
        if not self.speaker_embeddings:
            logger.warning("æ²¡æœ‰åŠ è½½è¯´è¯äººå£°çº¹æ¡£æ¡ˆï¼Œè·³è¿‡Resemblyzerå¢å¼º")
            return segments
        
        try:
            # åŠ è½½å®Œæ•´éŸ³é¢‘æ–‡ä»¶
            audio_data, sr = librosa.load(audio_file, sr=16000)
            
            enhanced_segments = []
            resemblyzer_matches = 0
            
            for segment in segments:
                start_time = segment.get('start', 0)
                end_time = segment.get('end', 0)
                original_speaker = segment.get('speaker', 'Unknown')
                
                # æå–éŸ³é¢‘ç‰‡æ®µçš„åµŒå…¥å‘é‡
                segment_embedding = self._extract_segment_embedding(audio_data, start_time, end_time, sr)
                
                # åˆ›å»ºå¢å¼ºçš„ç‰‡æ®µ
                enhanced_segment = segment.copy()
                
                if segment_embedding is not None:
                    # ä½¿ç”¨Resemblyzerè¯†åˆ«è¯´è¯äºº
                    identified_speaker, similarity = self._identify_speaker(segment_embedding)
                    
                    if identified_speaker:
                        # ResemblyzeræˆåŠŸè¯†åˆ«
                        enhanced_segment['speaker'] = identified_speaker
                        enhanced_segment['speaker_confidence'] = 'high'
                        enhanced_segment['recognition_method'] = 'resemblyzer'
                        enhanced_segment['similarity_score'] = float(similarity)
                        resemblyzer_matches += 1
                    else:
                        # Resemblyzeræœªè¯†åˆ«ï¼Œä¿æŒåŸæœ‰æ ‡ç­¾
                        enhanced_segment['speaker_confidence'] = 'medium'
                        enhanced_segment['recognition_method'] = 'pyannote'
                        enhanced_segment['similarity_score'] = 0.0
                else:
                    # æ— æ³•æå–åµŒå…¥å‘é‡ï¼Œä¿æŒåŸæœ‰æ ‡ç­¾
                    enhanced_segment['speaker_confidence'] = 'low'
                    enhanced_segment['recognition_method'] = 'pyannote'
                    enhanced_segment['similarity_score'] = 0.0
                
                enhanced_segments.append(enhanced_segment)
            
            success_rate = (resemblyzer_matches / len(segments)) * 100 if segments else 0
            logger.info(f"Resemblyzerè¯†åˆ«æˆåŠŸç‡: {success_rate:.1f}% ({resemblyzer_matches}/{len(segments)})")
            
            return enhanced_segments
            
        except Exception as e:
            logger.error(f"Resemblyzerå¢å¼ºè¯´è¯äººè¯†åˆ«å¤±è´¥: {e}")
            return segments  # è¿”å›åŸå§‹ç‰‡æ®µ
    
    def get_speaker_statistics(self, segments: List[Dict]) -> Dict:
        """
        è·å–è¯´è¯äººç»Ÿè®¡ä¿¡æ¯
        
        Args:
            segments: ç‰‡æ®µåˆ—è¡¨
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        stats = {
            'total_segments': len(segments),
            'speakers': {},
            'recognition_methods': {'resemblyzer': 0, 'pyannote': 0},
            'confidence_levels': {'high': 0, 'medium': 0, 'low': 0},
            'average_similarity': 0.0,
            'resemblyzer_success_rate': 0.0
        }
        
        total_similarity = 0.0
        resemblyzer_count = 0
        
        for segment in segments:
            speaker = segment.get('speaker', 'Unknown')
            method = segment.get('recognition_method', 'unknown')
            confidence = segment.get('speaker_confidence', 'low')
            similarity = segment.get('similarity_score', 0.0)
            
            # ç»Ÿè®¡è¯´è¯äºº
            if speaker not in stats['speakers']:
                stats['speakers'][speaker] = {
                    'segments': 0,
                    'total_duration': 0.0,
                    'average_similarity': 0.0,
                    'total_similarity': 0.0
                }
            
            stats['speakers'][speaker]['segments'] += 1
            duration = segment.get('end', 0) - segment.get('start', 0)
            stats['speakers'][speaker]['total_duration'] += duration
            stats['speakers'][speaker]['total_similarity'] += similarity
            
            # ç»Ÿè®¡è¯†åˆ«æ–¹æ³•
            if method in stats['recognition_methods']:
                stats['recognition_methods'][method] += 1
                if method == 'resemblyzer':
                    resemblyzer_count += 1
            
            # ç»Ÿè®¡ç½®ä¿¡åº¦
            if confidence in stats['confidence_levels']:
                stats['confidence_levels'][confidence] += 1
            
            total_similarity += similarity
        
        # è®¡ç®—å¹³å‡ç›¸ä¼¼åº¦
        if len(segments) > 0:
            stats['average_similarity'] = total_similarity / len(segments)
            stats['resemblyzer_success_rate'] = (resemblyzer_count / len(segments)) * 100
        
        # è®¡ç®—æ¯ä¸ªè¯´è¯äººçš„å¹³å‡ç›¸ä¼¼åº¦
        for speaker_stats in stats['speakers'].values():
            if speaker_stats['segments'] > 0:
                speaker_stats['average_similarity'] = speaker_stats['total_similarity'] / speaker_stats['segments']
        
        return stats
    
    def print_enhancement_summary(self, segments: List[Dict]):
        """æ‰“å°å¢å¼ºç»“æœæ‘˜è¦"""
        stats = self.get_speaker_statistics(segments)
        
        print("\n" + "="*60)
        print("Resemblyzerå£°çº¹è¯†åˆ«å¢å¼ºç»“æœ")
        print("="*60)
        
        print(f"æ€»ç‰‡æ®µæ•°: {stats['total_segments']}")
        print(f"è¯†åˆ«åˆ°çš„è¯´è¯äºº: {len(stats['speakers'])}")
        print(f"ResemblyzeræˆåŠŸç‡: {stats['resemblyzer_success_rate']:.1f}%")
        print(f"å¹³å‡ç›¸ä¼¼åº¦: {stats['average_similarity']:.3f}")
        
        print(f"\nè¯†åˆ«æ–¹æ³•ç»Ÿè®¡:")
        for method, count in stats['recognition_methods'].items():
            percentage = (count / stats['total_segments']) * 100 if stats['total_segments'] > 0 else 0
            print(f"  - {method}: {count} ({percentage:.1f}%)")
        
        print(f"\nç½®ä¿¡åº¦ç»Ÿè®¡:")
        for confidence, count in stats['confidence_levels'].items():
            percentage = (count / stats['total_segments']) * 100 if stats['total_segments'] > 0 else 0
            print(f"  - {confidence}: {count} ({percentage:.1f}%)")
        
        print(f"\nè¯´è¯äººå‘è¨€ç»Ÿè®¡:")
        for speaker, info in stats['speakers'].items():
            duration = info['total_duration']
            minutes = int(duration // 60)
            seconds = int(duration % 60)
            avg_sim = info['average_similarity']
            print(f"  - {speaker}: {info['segments']} ç‰‡æ®µ, {minutes}åˆ†{seconds}ç§’, å¹³å‡ç›¸ä¼¼åº¦: {avg_sim:.3f}")
        
        print("="*60)
    
    def get_known_speakers(self) -> List[str]:
        """è·å–å·²çŸ¥è¯´è¯äººåˆ—è¡¨"""
        return self.speaker_names.copy()
    
    def set_threshold(self, threshold: float):
        """è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼"""
        self.threshold = max(0.0, min(1.0, threshold))
        logger.info(f"ç›¸ä¼¼åº¦é˜ˆå€¼å·²è®¾ç½®ä¸º: {self.threshold}")
    
    def reload_speaker_profiles(self):
        """é‡æ–°åŠ è½½è¯´è¯äººå£°çº¹æ¡£æ¡ˆ"""
        print("ğŸ”„ æ­£åœ¨é‡æ–°åŠ è½½å£°çº¹åº“...")
        
        # æ¸…ç©ºç°æœ‰å£°çº¹
        self.speaker_embeddings.clear()
        self.speaker_names.clear()
        
        # é‡æ–°åŠ è½½
        self._load_speaker_profiles()
        
        print(f"âœ… å£°çº¹åº“é‡æ–°åŠ è½½å®Œæˆï¼ŒåŒ…å« {len(self.speaker_embeddings)} ä¸ªè¯´è¯äºº")
        return len(self.speaker_embeddings)
    
    def add_speaker_from_file(self, wav_file_path: str) -> bool:
        """
        ä»æ–‡ä»¶æ·»åŠ å•ä¸ªè¯´è¯äººå£°çº¹
        
        Args:
            wav_file_path: wavæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        wav_path = Path(wav_file_path)
        
        if not wav_path.exists():
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {wav_file_path}")
            return False
        
        if wav_path.suffix.lower() != '.wav':
            logger.error(f"åªæ”¯æŒwavæ–‡ä»¶: {wav_file_path}")
            return False
        
        speaker_name = wav_path.stem
        
        try:
            # åŠ è½½å’Œé¢„å¤„ç†éŸ³é¢‘
            wav, sr = librosa.load(str(wav_path), sr=16000)
            wav = preprocess_wav(wav)
            
            # æå–å£°çº¹åµŒå…¥å‘é‡
            embedding = self.voice_encoder.embed_utterance(wav)
            
            # æ·»åŠ åˆ°å£°çº¹åº“
            self.speaker_embeddings[speaker_name] = embedding
            if speaker_name not in self.speaker_names:
                self.speaker_names.append(speaker_name)
            
            logger.info(f"æˆåŠŸæ·»åŠ è¯´è¯äººå£°çº¹: {speaker_name}")
            return True
            
        except Exception as e:
            logger.error(f"æ·»åŠ è¯´è¯äºº {speaker_name} å¤±è´¥: {e}")
            return False


def demo():
    """æ¼”ç¤ºåŠŸèƒ½"""
    try:
        # åˆå§‹åŒ–Resemblyzerå£°çº¹è¯†åˆ«
        recognizer = ResemblyzerSpeakerRecognition()
        
        print(f"å·²çŸ¥è¯´è¯äºº: {recognizer.get_known_speakers()}")
        
        # æ¨¡æ‹Ÿä¸€äº›ç‰‡æ®µæ•°æ®
        test_segments = [
            {
                'start': 0.0,
                'end': 5.0,
                'text': 'å¤§å®¶å¥½ï¼Œæ¬¢è¿å‚åŠ ä»Šå¤©çš„ä¼šè®®ã€‚',
                'speaker': 'SPEAKER_00'
            },
            {
                'start': 5.0,
                'end': 10.0,
                'text': 'è°¢è°¢ä¸»æŒäººï¼Œæˆ‘æ¥ä»‹ç»ä¸€ä¸‹é¡¹ç›®è¿›å±•ã€‚',
                'speaker': 'SPEAKER_01'
            }
        ]
        
        print("\nåŸå§‹ç‰‡æ®µ:")
        for segment in test_segments:
            print(f"  {segment['speaker']}: {segment['text']}")
        
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®é™…çš„éŸ³é¢‘æ–‡ä»¶æ¥æµ‹è¯•
        # enhanced_segments = recognizer.enhance_speaker_identification(test_segments, "test.m4a")
        # recognizer.print_enhancement_summary(enhanced_segments)
        
    except Exception as e:
        print(f"æ¼”ç¤ºå¤±è´¥: {e}")


if __name__ == "__main__":
    demo()